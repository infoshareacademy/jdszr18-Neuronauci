{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8391901c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4982ff86",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = r\"FER-2013\\train\"\n",
    "test_path = r\"FER-2013\\test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed6f02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,               # Normalize pixel values from [0, 255] to [0, 1]\n",
    "                                    rotation_range=15,            # Randomly rotate images in the range of Â±15 degrees\n",
    "                                    width_shift_range=0.1,        # Randomly shift images horizontally by up to 10% of the width\n",
    "                                    height_shift_range=0.1,       # Randomly shift images vertically by up to 10% of the height\n",
    "                                    shear_range=0.1,              # Apply shear transformations (slanting the image)\n",
    "                                    zoom_range=0.1,               # Randomly zoom in/out by up to 10%\n",
    "                                    horizontal_flip=True,         # Randomly flip images horizontally (left-right)\n",
    "                                    fill_mode='nearest'           # Fill in missing pixels after transformation using the nearest pixel values\n",
    "                                    )\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_set = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(48, 48),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(48, 48),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb4bbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplary images\n",
    "x_batch, y_batch = next(train_set)\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.imshow(x_batch[i])\n",
    "    plt.title(f\"Class: {np.argmax(y_batch[i])}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding class weights to handle class imbalance\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_set.classes),\n",
    "    y=train_set.classes\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842bcfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base model\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n",
    "\n",
    "#Option 1: Freeze all layers //turned out to give lower accuracy\n",
    "#base_model.trainable = False  # Freeze for transfer learning\n",
    "\n",
    "#Option 2: Freeze all layers except the last 30 layers\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-30]:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "output = Dense(train_set.num_classes, activation='softmax')(x)\n",
    "\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3fb1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback that changes learning rate when model has stopped improving\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate = 0.0001, \n",
    "                          beta_1 = 0.9, beta_2 = 0.999),\n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#training\n",
    "history = model.fit(\n",
    "    train_set,\n",
    "    steps_per_epoch=len(train_set),\n",
    "    epochs=40,\n",
    "    validation_data=test_set,\n",
    "    validation_steps=len(test_set),\n",
    "    callbacks=[reduce_lr],\n",
    "    class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0226c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(accuracy) + 1) # get the number of epochs for X axsis\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(epochs, accuracy, color='blue', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, color='orange', label='Validation accuracy')\n",
    "plt.title('Training vs validation accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(epochs, loss, color='blue', label='Training loss')\n",
    "plt.plot(epochs, val_loss, color='orange', label='Validation loss')\n",
    "plt.title('Training vs validation loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e8c65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(test_set)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print(classification_report(test_set.classes, y_pred))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
